<html>
  <body>
    <div>3 May 2023: BYOD</div>
    <div>As  a senior, I won't be impacted by this school policy change. I do, however, have a sister who will be impacted, as well as many underclassman friends. Starting next year, students will all be expected to use a school chromebook. This impacts many people, and not a single person is impacted in a positive way. The students who have already bought their own devices may now feel that they have wasted money on a good laptop they will no longer be using. The school has spent extra money on computers that they don't need. Even more then that, the chromebooks aren't even good chromebooks, much less computers in general. THey don't allow you to run programs on them, which is required in some classes, like computer science. They are often very slow and hard to work with. Even their basic functionality, such as the mouse pad, is different from normal commputers, which creates a period of adjustment for students where they need to retrain their musle memeory both now and later when they return to their regular computers. Along with that, some classes, like comp sci, require work at home that requires a computer. It's really easy to set everything up in class to work well at home when we can bring our own computers, but taking that away will make it much more complicted to both set up and to fix if that's needed. This will also hurt students later in life if all they are used to using is a chromebook. Because they are so different to typical computers, they will need to retrain everything to readjust. </div>
    <div>5 May 2023: AI regulations</div>
    <div>Government AI regulation should be treated on a case-by-case basis. Some AI's are more capable than others. Why should the government put equal focus on an AI that helps with basic schoolwork as an AI that can answer any question in great detail? The answer is it shouldn't. I think that all AI's shold be known by the government, but by their nature some AIs will need more restrictions than others. There should be some grading scale of what possible danger an AI could pose, and the results of that grading would tell the government how much regulation any particular AI should have. AI can be a very powerful tool that can lead to great good happening in the world, but some people would instead use it to cause harm. Because of this, the government needs to regulate AI, at least a little bit. If this were a perfect world with perfect people, that wouldn't be needed. Instead, our world and people are imperfect, so a powerful and accessable tool like AI needs regulation to prevent some people from using it to cause harm. </div>
  </body>
</html>
